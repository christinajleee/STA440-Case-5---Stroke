---
title: "Factors that Influence Clinical Outcomes After Ischemic Stroke"
author:
  - name: "Eunice Lee"
  - name: "Diane Lin"
  - name: "Christina Lee"
format: 
  pdf:
    documentclass: article
    toc: true
    number-sections: true
    keep-tex: false
---

# Background:

Stroke is a leading cause of death and a big cause of chronic disability in the United States, and because it is commonly painless, patients can lack the recognition of the symptoms. Therefore, we are tasked with seeing how to accelerate the process of acute stroke care delivery by reducing the time needed to make treatment decisions and providing reperfusion interventions with either thrombolytic (TPA) or mechanical thrombectomy, or both. The program included promoting education in the community and clinical training for EMS providers. The study was conducted over 2019-2020 on a quarterly basis, where the first two quarters included program planning (baseline), the next four quarters included the implementation of the program, and the last two quarters represented a period of full implementation.

# Research Question:

Is there evidence that outcomes improved (measured by if patients were discharged to their home or a rehabilitation facility as opposed to other outcomes) over the course of the study, from baseline to end–of–study?”

# Data:

## Missing Data:

Five variables were missing information from this data set. The outcome variable, homeOrRehab, was missing 3% of observations. Because outcome missingness complicates interpretation and cannot be reliably imputed under our study design, these observations were excluded from the analysis. The remaining missingness occurred in four covariates: Age, PreHospNotify (whether EMS notified the hospital prior to arrival), EMSVsCar (mode of arrival), and Race2. Missingness was not uniformly distributed. Age had the highest proportion of missing observations at 47%, followed by PreHospNotify (12%), EMSVsCar (5%), and Race2 (4%).

When examining for patterns in missing data, it was noticed that Age was completely missing from observations taken at sites with IDs 170, 150, and 140. This strongly suggests site-level data collection issues rather than patient-level characteristics driving missingness. Furthermore, PreHospNotify and EMSvsCar were most highly correlated for missing data at 0.36, while least correlated were Race and PreHospNotify.

# EDA:

Our EDA focused on understanding how treatment type, complications, and demographic factors relate to the likelihood of a favorable outcome (defined as discharge to home or rehabilitation). At baseline (control phase), patients who received thrombectomy only had the lowest proportion of favorable outcomes. Patients treated with TPA only or both procedures had higher and relatively similar home/rehab rates.

After full implementation of the intervention program, outcomes improved for all groups, but the relative ordering persisted. TPA-only patients continued to have the best outcomes, while thrombectomy-only patients still had the poorest outcomes, though their performance improved compared to baseline. Interestingly, patients who received both procedures performed moderately well but not as well as patients receiving TPA alone, and slightly worse than the same group earlier in the study.

Across all operation types, absence of complications was strongly associated with better outcomes. In contrast, any complication TPA-related, thrombectomy-related, or both, substantially reduced the likelihood of discharge to home or rehab. Finally, one patient was observed to have received both procedures, and complications occurred for both. This individual was not discharged to home or rehab.

# Frequentist Model:

For our frequentist model, we used Multiple Imputation by Chained Equations (MICE), which is a statistical method for dealing with missing data by creating multiple complete datasets instead of just one. For the model, the predictor variables included demographic factors (Age, Gender, Race), clinical treatment indicators (hadTPA, hadThrombectomy), complication variables (tpaComplic, thrComplic), and information about the study quarter (Time2). We also included siteID to account for differences across the sites. PreHospNotify (whether EMS alerted the hospital before arrival) and EMSvsCar were also included as variables. The outcome variable we used is homeOrRehab, which helps us see if the patient had a positive outcome of either going home or enrolling in rehabilitation services depending on the predictor variable factors.

In order to account for the variables with the most missing data, we started by fitting a linear regression model predicting Age from the available demographic and clinical predictors. For the rows with missing Age, the model predicts the most reasonable values and fills in the missing entries. To add on, a linear regression model makes sense here because Age is a continuous variable. Next, we imputed PreHospNotify using a logistic regression model since this is a binary variable. The model estimated the probability that PreHospNotify = 1 for each case with missing data, and then we used draws from Bernoulli to generate the imputed values. This method makes sure to include realistic binary variation and preserve uncertainty compared to deterministically rounding probabilities. We followed the same method for EMSvsCar, which is also a binary predictor. We fit a logistic regression using all of the available predictors, calculated predicted probabilities for the missing cases, and used random draws from a Bernoulli distribution to create the realistic imputed values. This approach maintains the relationships among variables across the imputed datasets, which is important for unbiased estimation in a frequentist framework.

Once the chained imputations were complete, we generated fully imputed datasets and used these to compute correlations between each predictor and the outcome variable. Continuous variables were evaluated with Pearson correlations, and the ordinal predictors were evaluated using Spearman correlations. By combining the imputed datasets and using the correlations to create the full model, we made sure that our analysis accounted for the uncertainty introduced by the missing data.

$$
\begin{aligned}
\operatorname{log}\!\big(\Pr(\text{Home/Rehab})\big)
&= \beta_0 
  + \beta_1(\text{Age})
  + \beta_2(\text{Pre-hospital notification}) \\
&\quad + \beta_3(\text{EMS transport})
  + \beta_4(\text{Program phase}) \\
&\quad + \text{Gender effects}
  + \text{Race effects}
  + \text{Hospital site effects}
  + \text{Time-period effects} \\
&\quad + \beta_5(\text{Thrombectomy})
  + \beta_6(\text{tPA})
  + \beta_7(\text{tPA complication})
  + \beta_8(\text{Thrombectomy complication})
\end{aligned}
$$

Based on our ROC curve, the AUC was 0.85 (Figure 1), which indicates that the model can well distinguish between patients who were discharged home and those who were sent to rehabilitation services. The residuals show several signs of model misfit including there being a curvature pattern being represented across the fitted probabilities and Age (Figure 2) and the QQ-plot showing deviations from the reference line in the tails (Figure 3). These patterns suggest that the logistic model is not capturing all of the underlying structure in the data. Additionally, using MICE for the frequentist model also relies on the assumption that the missing data are missing at random. We cannot confirm that this assumption is true, and this could affect both the imputations and the model estimates. Because of this, we believe that a Bayesian approach which can incorporate uncertainty directly and allow more flexible modeling, may be a better fit for our data and research goals.

# Bayesian Model:

Rationale The goal of this case study was to evaluate how patient characteristics, treatments, and timing relative to the improve program relate to the likelihood of being discharged or sent to inpatient rehabilitation. As our outcome is a binary variable, we chose to use a logistic regression model. However, our EDA showed that the 9 different stroke centers had significant variation across sites with different baseline outcome rates. To account for this clustering, we decided to use a hierarchical model with a random intercept for each site to allow each hospital to have its own baseline probability of positive outcomes, while retrieving information cross-site.

We chose to include a program indicator to capture the change between pre- and post-implementation periods while controlling for other variables, in order to test if outcomes improved after implementation of the program. Additional covariates such as age, gender, EMS arrival, tPA administration, and thrombectomy were included, as our EDA suggested their association with discharge outcomes. To fit this hierarchical model, we decided to implement a Bayesian model with weakly informative priors to later obtain full posterior uncertainty for all effects, including the program indicator.

Implementation We fit a Bayesian hierarchical logistic regression model in JAGS as the following:

## Outcome Model

$$
\begin{aligned}
Y_i &\sim \text{Bernoulli}(p_i) \\[6pt]
\text{logit}(p_i)
&= \alpha_{\text{site}[i]} + \beta_0 \\[6pt]
&\quad + \beta_1\,\text{Program}_i
       + \beta_2\,A_i^\ast
       + \beta_3\,\text{Female}_i \\[4pt]
&\quad + \beta_4\,\text{EMS}_i
       + \beta_5\,\text{TPA}_i
       + \beta_6\,\text{Thrombectomy}_i
\end{aligned}
$$

## Imputation Model (Age)

$$
\begin{aligned}
A_i^\ast &\sim \mathcal{N}(\mu_{A,i}, \sigma_A^2) \\[6pt]
\mu_{A,i}
&= \gamma_0
 + \gamma_1\,\text{Female}_i
 + \gamma_2\,\text{Program}_i
 + \gamma_3\,\text{EMS}_i
\end{aligned}
$$

## Priors

$$
\begin{aligned}
\beta_k &\sim \mathcal{N}(0, 10^2), 
&\qquad k &= 0,\dots,6 \\[6pt]
\gamma_\ell &\sim \mathcal{N}(0, 10^2),
&\qquad \ell &= 0,\dots,3 \\[6pt]
\alpha_j &\sim \mathcal{N}(\mu_\alpha, \sigma_\alpha^2),
&\qquad j &= 1,\dots,J \\[6pt]
\mu_\alpha &\sim \mathcal{N}(0, 10^2) \\[6pt]
\sigma_\alpha &\sim \text{Half-N}(0, 2.5), \\[2pt]
\sigma_A &\sim \text{Half-N}(0, 20)
\end{aligned}
$$

Age was centered and scaled to improve mixing, and a random intercept was assigned to each site to allow different baseline outcomes across centers. We incorporated normally distributed priors to all coefficients, as well as site-level intercepts governed by hyperparameters. This model was fit with 4 MCMC chains with 5000 iterations each, setting a burn-in period of 2000, for a final set of posterior samples for estimation.

# Evaluation:

## MCMC Diagnostics:

To evaluate convergence and sampling efficiency of our Bayesian hierarchical model, we examined trace plots, ACF plots, and effective sample sizes for all model parameters. The fixed-effect regression coefficients displayed strong convergence with overlapping chains (Figure 10), and the autocorrelation functions rapidly fell to zero within less than 5 lags (Figure 13). Also, most β and γ parameters achieved effective sample sizes between approximately 5,400 and 8,200, indicating efficient mixing and minimal dependence between successive samples (Figure 9). However, the random-effects hyper parameters showed slower mixing and some autocorrelation (Figure 12), as μ_alpha showed more stickiness and poor movement across the window in the trace plot. This resulted in an ESS of approximately 22 (Figure 9), suggesting that posterior inference for μ_alpha carries higher Monte Carlo uncertainty. Such limitations in convergence likely reflect the large heterogeneity across hospital sites, indicating that the challenge of estimating random intercepts with limited sample size and missing data from some centers. Overall, our posterior summaries for the fixed effects parameters showed as highly reliable, while conclusions regarding site-level variability held some uncertainty.

## Model Evaluation:

To assess how well our hierarchical logistic regression model captured the observed patterns in discharge outcomes, we used posterior predictive diagnostics and examined our residuals. Our final model achieved an AUC of 0.73 (Figure 4) for patients discharged home or to rehab versus other outcomes, implying that its classification performance was acceptable. However, our residual plots revealed some error as plotting the deviance residuals against fitted probabilities and against age showed strong curvature (Figure 5 and 6). This indicated that even with the log transformation, the model did not perfectly capture nonlinear age effects or shifts in risk at the extreme ends of probability. Our residual distributions also varied systematically across the 9 hospital sites (Figure 7), consistent with our MCMC results that site-level heterogeneity played a large role. Additionally, our QQ-plot (Figure 8) demonstrated heavy tails, suggesting that our model could be underestimating some extreme-end observations. Overall, our diagnostic result indicated that the model well-captured broad trends and produced relatively accurate predictions, but did not perfectly predict the fine-tuned nonlinear age effects and substantial cross-site variations.

## Results:

The posterior distribution for the program indicator had a mean of approximately 0.16, with a 95% credible interval that included 0 (Figure 4). As such, this estimate suggests a modest positive association between program implementation and improved discharge outcomes, though the uncertainty interval indicates that the magnitude of this improvement is small and not strongly distinguishable from no effect. In other words, while outcomes trend upward over time, the statistical evidence for a meaningful effect attributable solely to the program is weak.

Several other covariates show consistent relationships with the outcome. Age exhibits a negative association with the probability of home/rehab discharge (Figure 4), indicating older patients have lower odds of receiving a favorable outcome, consistent with both our EDA and clinical expectations. EMS arrivals were associated with worse outcomes (Figure 4), which likely reflects underlying case severity, as patients arriving by EM tend to be more severely impaired.

Finally, we found a substantial site-level heterogeneity. We discovered that the variance in random intercepts is larger than the magnitude of the program effect (Figure 4), implying that the hospital itself plays a more influential role in discharge outcomes than the intervention program.

# Shortcomings/Assumptions:

Several limitations affect the strength and interpretability of our findings. First, the high missingness of age, our most predictive covariate, as well as the fact that it was completely missing for several sites, reduces confidence in age-related estimates, even with the imputation of our Bayesian model. Our models both also assume Missing at Random. This assumption, if inaccurate, may bias parameter estimates.

Our model itself showed curvature in residual plots with respect to age and fitted values, heavy tails and site-level structure, indicating that the logistic model may have been too restrictive. Furthermore, MCMC diagnostics revealed that mu_alpha mixed poorly and showed high autocorrelation with low ESS.

# Conclusion:

Overall, the hierarchical Bayesian model suggests that patient outcomes improved slightly over the study period, but the estimated program effect is small relative to variation explained by patient characteristics and hospital site. Age and treatment modality (particularly thrombolytic therapy) are strong predictors of favorable discharge, whereas thrombectomy and EMS arrival show weaker or more context-dependent associations. The large magnitude of site-level variation indicates that institutional differences such as workflow efficiency, staffing, diagnostic capabilities, or local protocols, likely play a larger role in shaping patient outcomes than the system-wide educational and training intervention alone.

# Appendix

```{r echo=FALSE, include=FALSE}
# --- Combined EDA + Frequentist model + diagnostics chunk (code hidden on render) ---

library(tidyverse)
library(ggplot2)
library(naniar)
library(corrplot)
library(gridExtra)
library(broom)
library(car)
library(pROC)
library(patchwork)
library(scales)

# Load dataset (adjust path if needed)

# If your dataset is already in the environment as `x`, you can comment out the load line.

if (file.exists("strokeStudy.RData")) {
load("strokeStudy.RData")  # loads object 'x' (expected)
}

# Basic dataset checks

cat("DATASET OVERVIEW\n")
cat("Dataset name: x\n")
if (exists("x")) {
cat("Dimensions:", dim(x), "\n")
cat("Variables:", paste(names(x), collapse = ", "), "\n\n")
} else {
stop("Data frame 'x' not found in the environment.")
}

cat("BASIC DATA OVERVIEW\n")
str(x)
summary(x)

# MISSING DATA ANALYSIS

cat("\nMISSING DATA ANALYSIS\n")
miss_summary <- miss_var_summary(x)
print(miss_summary)

p1 <- gg_miss_var(x) +
labs(title = "Missing Data by Variable")

missing_by_time <- x %>%
group_by(Time2) %>%
summarise(across(everything(), ~sum(is.na(.))/n() * 100)) %>%
pivot_longer(cols = -Time2, names_to = "variable", values_to = "missing_pct")

p2 <- ggplot(missing_by_time, aes(x = Time2, y = missing_pct, color = variable)) +
geom_line(aes(group = variable)) +
geom_point() +
labs(title = "Missing Data Patterns Over Time", y = "Missing (%)", x = "Study Quarter") +
theme(legend.position = "none")

# Outcome overview

cat("\nOUTCOME VARIABLE: homeOrRehab\n")
outcome_table <- table(x$homeOrRehab, useNA = "always")
outcome_prop <- prop.table(table(x$homeOrRehab))
print(outcome_table)
print(outcome_prop)

p3 <- ggplot(x, aes(x = homeOrRehab)) +
geom_bar(fill = "steelblue", alpha = 0.7) +
labs(title = "Distribution of Discharge Disposition", x = "Home or Rehabilitation", y = "Count") +
geom_text(stat = 'count', aes(label = ..count..), vjust = -0.5)

outcome_time <- x %>%
group_by(Time2, homeOrRehab) %>%
summarise(count = n(), .groups = "drop") %>%
group_by(Time2) %>%
mutate(prop = count/sum(count)) %>%
filter(homeOrRehab == TRUE)

p4 <- ggplot(outcome_time, aes(x = Time2, y = prop)) +
geom_col(fill = "darkgreen", alpha = 0.7) +
geom_text(aes(label = paste0(round(prop*100, 1), "%")), vjust = -0.5) +
labs(title = "Proportion of Good Outcomes by Study Quarter", y = "Proportion with Good Outcome", x = "Study Quarter") +
ylim(0, 1)

# Demographics

p5 <- ggplot(x, aes(x = homeOrRehab, y = Age, fill = homeOrRehab)) +
geom_boxplot(alpha = 0.7) +
labs(title = "Age Distribution by Outcome", x = "Home or Rehabilitation", y = "Age") +
theme(legend.position = "none")

gender_outcome <- x %>%
count(Gender, homeOrRehab) %>%
group_by(Gender) %>%
mutate(prop = n/sum(n))

p6 <- ggplot(gender_outcome, aes(x = Gender, y = prop, fill = homeOrRehab)) +
geom_bar(stat = "identity", position = "fill") +
labs(title = "Outcome Distribution by Gender", y = "Proportion") +
scale_y_continuous(labels = scales::percent)

race_outcome <- x %>%
count(Race2, homeOrRehab) %>%
group_by(Race2) %>%
mutate(prop = n/sum(n))

p7 <- ggplot(race_outcome, aes(x = Race2, y = prop, fill = homeOrRehab)) +
geom_bar(stat = "identity", position = "fill") +
labs(title = "Outcome Distribution by Race", y = "Proportion") +
scale_y_continuous(labels = scales::percent) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Clinical/process variables

ems_outcome <- x %>%
count(EMSvsCar, homeOrRehab) %>%
group_by(EMSvsCar) %>%
mutate(prop = n/sum(n))

p8 <- ggplot(ems_outcome, aes(x = factor(EMSvsCar), y = prop, fill = homeOrRehab)) +
geom_bar(stat = "identity", position = "fill") +
labs(title = "Outcome by Arrival Mode", x = "Arrival by EMS (1=Yes, 0=No)", y = "Proportion") +
scale_y_continuous(labels = scales::percent)

treatment_plots <- list()
treatment_vars <- c("hadThrombectomy", "hadTPA", "PreHospNotify")

for(i in seq_along(treatment_vars)) {
var <- treatment_vars[i]
if (! (var %in% names(x))) next
treatment_data <- x %>%
count(!!sym(var), homeOrRehab) %>%
group_by(!!sym(var)) %>%
mutate(prop = n/sum(n))

treatment_plots[[i]] <- ggplot(treatment_data,
aes(x = factor(!!sym(var)), y = prop, fill = homeOrRehab)) +
geom_bar(stat = "identity", position = "fill") +
labs(title = paste("Outcome by", var), x = var, y = "Proportion") +
scale_y_continuous(labels = scales::percent)
}

# Complications

cat("\nCOMPLICATION ANALYSIS\n")
if("tpaComplic" %in% names(x)) {
print(table(x$tpaComplic, useNA = "always"))
}
if("thrComplic" %in% names(x)) {
print(table(x$thrComplic, useNA = "always"))
}

# Site-specific analysis

site_outcome <- x %>%
group_by(siteID, homeOrRehab) %>%
summarise(count = n(), .groups = "drop") %>%
group_by(siteID) %>%
mutate(prop_good = count/sum(count)) %>%
filter(homeOrRehab == TRUE)

p9 <- ggplot(site_outcome, aes(x = factor(siteID), y = prop_good)) +
geom_col(fill = "purple", alpha = 0.7) +
geom_text(aes(label = paste0(round(prop_good*100, 1), "%")), vjust = -0.5) +
labs(title = "Proportion of Good Outcomes by Site", y = "Proportion with Good Outcome", x = "Site ID") +
ylim(0, 1)

# Arrange and print summary plots

grid.arrange(p3, p4, p5, p6, ncol = 2)
grid.arrange(p7, p8, p9, ncol = 2)
for(plot in treatment_plots) {
if(!is.null(plot)) print(plot)
}

# Demographic summary table

cat("\nSUMMARY STATISTICS TABLE\n")
demographic_summary <- x %>%
group_by(homeOrRehab) %>%
summarise(
n = n(),
mean_age = mean(Age, na.rm = TRUE),
sd_age = sd(Age, na.rm = TRUE),
.groups = 'drop'
)
print(demographic_summary)

# Time trend analysis

cat("\nTIME TREND ANALYSIS FOR PROGRAM EFFECTIVENESS\n")
x <- x %>%
mutate(period = case_when(
Time2 %in% 1:2 ~ "Baseline",
Time2 %in% 3:6 ~ "Implementation",
Time2 %in% 7:8 ~ "End-of-Study",
TRUE ~ "Other"
))

period_outcome <- x %>%
group_by(period, homeOrRehab) %>%
summarise(count = n(), .groups = "drop") %>%
group_by(period) %>%
mutate(prop = count/sum(count), total = sum(count)) %>%
filter(homeOrRehab == TRUE)

print(period_outcome)

p10 <- ggplot(period_outcome, aes(x = period, y = prop)) +
geom_col(fill = "orange", alpha = 0.7) +
geom_text(aes(label = paste0(round(prop*100, 1), "%\n(n=", total, ")")), vjust = -0.5) +
labs(title = "Good Outcomes by Study Period", y = "Proportion with Good Outcome", x = "Study Period") +
ylim(0, 1)

print(p10)

# Correlation analysis (numeric)

cat("\nCORRELATION ANALYSIS\n")
numeric_data <- x %>%
select(where(is.numeric)) %>%
select(-any_of(c("siteID")))

if (ncol(numeric_data) > 1) {
cor_matrix <- cor(numeric_data, use = "pairwise.complete.obs")
corrplot(cor_matrix, method = "circle", type = "upper")
}

# -----------------------------

# Frequentist modeling pipeline

# -----------------------------

# Make working copy and create numeric outcome

df <- x
df <- df %>%
mutate(
homeOrRehab_num = case_when(
is.numeric(homeOrRehab) ~ as.integer(homeOrRehab),
is.logical(homeOrRehab) ~ as.integer(homeOrRehab),
toupper(as.character(homeOrRehab)) %in% c("YES","1","TRUE") ~ 1L,
toupper(as.character(homeOrRehab)) %in% c("NO","0","FALSE") ~ 0L,
TRUE ~ NA_integer_
)
)

# Impute Age (simple deterministic imputation)

lm_age <- lm(Age ~ Gender + Race2 + Time2 + hadThrombectomy + hadTPA + tpaComplic + thrComplic + homeOrRehab_num,
data = df, na.action = na.exclude)
age_na_idx <- which(is.na(df$Age))
if (length(age_na_idx) > 0) {
pred_age <- predict(lm_age, newdata = df[age_na_idx, ], se.fit = FALSE)
df$Age[age_na_idx] <- pred_age
}

# Impute PreHospNotify (logistic, stochastic)

df <- df %>%
mutate(
PreHospNotify_bin = case_when(
is.numeric(PreHospNotify) ~ as.integer(PreHospNotify),
is.logical(PreHospNotify) ~ as.integer(PreHospNotify),
toupper(as.character(PreHospNotify)) %in% c("YES","1","TRUE") ~ 1L,
toupper(as.character(PreHospNotify)) %in% c("NO","0","FALSE") ~ 0L,
TRUE ~ NA_integer_
)
)

glm_pre <- glm(PreHospNotify_bin ~ Age + Gender + Race2 + siteID + Time2 + hadThrombectomy + hadTPA + tpaComplic + thrComplic + homeOrRehab_num,
data = df, family = binomial(), na.action = na.exclude)
pre_na_idx <- which(is.na(df$PreHospNotify_bin))
if (length(pre_na_idx) > 0) {
p_hat <- predict(glm_pre, newdata = df[pre_na_idx, ], type = "response")
set.seed(123)
df$PreHospNotify_bin[pre_na_idx] <- rbinom(length(p_hat), size = 1, prob = p_hat)
}
df <- df %>% mutate(PreHospNotify_imp = if_else(is.na(PreHospNotify), as.character(PreHospNotify_bin), as.character(PreHospNotify)))

# Impute EMSvsCar (logistic, stochastic)

df <- df %>%
mutate(
EMSvsCar_bin = case_when(
is.numeric(EMSvsCar) ~ as.integer(EMSvsCar),
is.logical(EMSvsCar) ~ as.integer(EMSvsCar),
toupper(as.character(EMSvsCar)) %in% c("YES","1","TRUE") ~ 1L,
toupper(as.character(EMSvsCar)) %in% c("NO","0","FALSE") ~ 0L,
TRUE ~ NA_integer_
)
)

glm_ems <- glm(EMSvsCar_bin ~ Age + PreHospNotify_bin + Gender + Race2 + siteID + Time2 + hadThrombectomy + hadTPA + tpaComplic + thrComplic + homeOrRehab_num,
data = df, family = binomial(), na.action = na.exclude)
ems_na_idx <- which(is.na(df$EMSvsCar_bin))
if (length(ems_na_idx) > 0) {
p_hat_ems <- predict(glm_ems, newdata = df[ems_na_idx, ], type = "response")
set.seed(456)
df$EMSvsCar_bin[ems_na_idx] <- rbinom(length(p_hat_ems), size = 1, prob = p_hat_ems)
}
df <- df %>% mutate(EMSvsCar_imp = if_else(is.na(EMSvsCar), as.character(EMSvsCar_bin), as.character(EMSvsCar)))

# Create df_imputed for modeling

df_imputed <- df %>%
mutate(Age_imp = Age,
PreHospNotify_imp_num = as.integer(as.character(PreHospNotify_bin)),
EMSvsCar_imp_num = as.integer(as.character(EMSvsCar_bin))
)

# Fit final GLM (without phase_group here; later phase mapping code can add it)

df_imputed <- df_imputed %>%
mutate(
homeOrRehab_num = as.integer(homeOrRehab_num),
Age_imp = as.numeric(Age_imp),
PreHospNotify_imp_num = as.integer(PreHospNotify_imp_num),
EMSvsCar_imp_num = as.integer(EMSvsCar_imp_num),
Gender = as.factor(Gender),
Race2 = as.factor(Race2),
siteID = as.factor(siteID),
Time2 = as.factor(Time2),
hadThrombectomy = as.factor(hadThrombectomy),
hadTPA = as.factor(hadTPA),
tpaComplic = as.factor(tpaComplic),
thrComplic = as.factor(thrComplic)
)

predictors <- c("Age_imp","PreHospNotify_imp_num","EMSvsCar_imp_num","Gender","Race2","siteID","Time2","hadThrombectomy","hadTPA","tpaComplic","thrComplic")
predictors <- predictors[predictors %in% names(df_imputed)]
fmla <- as.formula(paste("homeOrRehab_num ~", paste(predictors, collapse = " + ")))
final_glm <- glm(fmla, data = df_imputed, family = binomial(), na.action = na.exclude)

# Model summary and ORs

summary(final_glm)
or_table <- broom::tidy(final_glm, conf.int = TRUE) %>%
mutate(OR = exp(estimate), OR_low = exp(conf.low), OR_high = exp(conf.high)) %>%
select(term, estimate, OR, OR_low, OR_high, p.value)
print(or_table)

# VIF

vif_vals <- tryCatch(car::vif(final_glm), error = function(e) { message("VIF computation failed: ", e$message); NULL })
print(vif_vals)

# ROC/AUC for the fitted model

df_imputed <- df_imputed %>% mutate(pred_prob = predict(final_glm, type = "response"))
roc_obj <- pROC::roc(df_imputed$homeOrRehab_num, df_imputed$pred_prob, quiet = TRUE)
auc_val <- pROC::auc(roc_obj)
cat("AUC =", round(as.numeric(auc_val), 3), "\n")
plot(roc_obj, main = paste0("ROC (AUC = ", round(as.numeric(auc_val),3), ")"))

# Confusion table

threshold <- 0.5
df_imputed <- df_imputed %>% mutate(pred_class = if_else(pred_prob >= threshold, 1L, 0L))
table_truth_pred <- table(Observed = df_imputed$homeOrRehab_num, Predicted = df_imputed$pred_class)
print(table_truth_pred)

# Phase mapping and final model with phase_group (if desired)

control_qtrs <- c("Y1Q1", "Y1Q2")
impl_qtrs    <- c("Y1Q3", "Y1Q4", "Y2Q1", "Y2Q2")
treat_qtrs   <- c("Y2Q3", "Y2Q4")
assign_phase <- function(time2) {
if (is.na(time2)) return(NA_character_)
t <- as.character(time2)
if (t %in% treat_qtrs) return("treatment")
if (t %in% impl_qtrs)  return("implementation")
if (t %in% control_qtrs) return("control")
return(NA_character_)
}
if("Time2" %in% names(df_imputed)) {
df_imputed <- df_imputed %>%
mutate(Time2 = as.character(Time2),
phase_group = vapply(Time2, assign_phase, FUN.VALUE = character(1)),
phase_group = factor(phase_group, levels = c("control", "implementation", "treatment"))
)

# if you want to include phase_group in a model:

if ("phase_group" %in% names(df_imputed)) {
predictors2 <- c(predictors, "phase_group")
predictors2 <- predictors2[predictors2 %in% names(df_imputed)]
fmla2 <- as.formula(paste("homeOrRehab_num ~", paste(predictors2, collapse = " + ")))
final_glm_phase <- glm(fmla2, data = df_imputed, family = binomial(), na.action = na.exclude)
df_imputed <- df_imputed %>% mutate(pred_prob_phase = predict(final_glm_phase, type = "response"))
roc_obj_phase <- pROC::roc(df_imputed$homeOrRehab_num, df_imputed$pred_prob_phase, quiet = TRUE)
cat("AUC (phase model) =", round(as.numeric(pROC::auc(roc_obj_phase)), 3), "\n")
plot(roc_obj_phase, main = paste0("ROC (AUC = ", round(as.numeric(pROC::auc(roc_obj_phase)),3), ")"))
}
}

# Diagnostics: compute residuals and diagnostic plots

diag_df <- df_imputed %>%
mutate(
fitted = predict(final_glm, type = "response"),
dev_resid = residuals(final_glm, type = "deviance"),
pear_resid = residuals(final_glm, type = "pearson"),
raw_resid = residuals(final_glm, type = "response"),
leverage = hatvalues(final_glm),
cooks = cooks.distance(final_glm),
obs_id = row_number()
)

n <- nrow(diag_df)
cooks_thresh <- 4 / n

p1 <- ggplot(diag_df, aes(x = fitted, y = dev_resid)) +
geom_hline(yintercept = 0, color = "grey40") +
geom_point(alpha = 0.6) +
geom_smooth(method = "loess", se = FALSE, color = "darkred") +
labs(x = "Fitted probability", y = "Deviance residuals", title = "Deviance residuals vs Fitted") +
theme_minimal()

p2 <- ggplot(diag_df, aes(sample = dev_resid)) +
stat_qq(alpha = 0.6) +
stat_qq_line(color = "darkblue") +
labs(title = "QQ-plot of deviance residuals") +
theme_minimal()

p3 <- ggplot(diag_df, aes(x = pear_resid)) +
geom_histogram(aes(y = ..density..), bins = 30, fill = "steelblue", alpha = 0.6) +
geom_density(color = "darkred") +
labs(x = "Pearson residuals", title = "Distribution of Pearson residuals") +
theme_minimal()

p4 <- ggplot(diag_df, aes(x = leverage, y = dev_resid)) +
geom_point(aes(size = cooks), alpha = 0.6) +
scale_size_continuous(range = c(1, 6), name = "Cook's D") +
geom_text(data = subset(diag_df, cooks > cooks_thresh), aes(label = obs_id), vjust = -1.1, size = 3, color = "darkred") +
geom_hline(yintercept = 0, color = "grey40") +
labs(x = "Leverage (hat values)", y = "Deviance residuals", title = "Residuals vs Leverage (Cook's D sized)") +
theme_minimal()

p5 <- ggplot(diag_df, aes(x = reorder(obs_id, -cooks), y = cooks)) +
geom_col(fill = "lightblue") +
geom_hline(yintercept = cooks_thresh, color = "red", linetype = "dashed") +
labs(x = "Observation (ordered by Cook's D)", y = "Cook's distance", title = paste0("Cook's distance (threshold = ", round(cooks_thresh, 4), ")")) +
theme_minimal() + theme(axis.text.x = element_blank())

# Display diagnostic grid

(p1 | p2) / (p3 | p4) / p5 + plot_layout(heights = c(1,1,0.7))

# Plot residuals vs Age only

ggplot(diag_df, aes(x = Age_imp, y = dev_resid)) +
geom_hline(yintercept = 0, color = "gray50") +
geom_point(alpha = 0.4, size = 1.3) +
geom_smooth(method = "loess", se = FALSE, color = "red") +
labs(title = "Residuals vs Age", x = "Age", y = "Deviance residual") +
theme_minimal()

# End of combined chunk
```

```{r echo=FALSE, include=FALSE}
# ---------------------------
# Bayesian stroke model - Final specification with Age sub-model
# ---------------------------

# packages
if (!requireNamespace("R2jags", quietly = TRUE)) install.packages("R2jags")
if (!requireNamespace("coda", quietly = TRUE)) install.packages("coda")
if (!requireNamespace("dplyr", quietly = TRUE)) install.packages("dplyr")
if (!requireNamespace("pROC", quietly = TRUE)) install.packages("pROC")

library(R2jags)
library(coda)
library(dplyr)
library(pROC)

# ---------- 0. load strokeStudy.RData ----------
obj_names <- load("strokeStudy.RData")
message("Loaded objects: ", paste(obj_names, collapse = ", "))

if ("strokeStudy" %in% obj_names) {
  strokeStudy <- get("strokeStudy")
} else {
  possible <- obj_names[sapply(obj_names, function(n) is.data.frame(get(n)))]
  if (length(possible) == 0) stop("No data.frame found in strokeStudy.RData.")
  strokeStudy <- get(possible[1])
  message("Using object '", possible[1], "' as strokeStudy.")
}

# ---------- 1. Data preparation ----------
df <- strokeStudy

required_cols <- c("homeOrRehab","siteID","Time2","Age","Gender","EMSvsCar","hadTPA","hadThrombectomy")
missing_cols <- setdiff(required_cols, names(df))
if (length(missing_cols) > 0) stop("Missing required columns: ", paste(missing_cols, collapse = ", "))

# Outcome: Y_i = 1 if discharged home or to inpatient rehab, 0 otherwise
df$y <- as.integer(
  (is.logical(df$homeOrRehab) & df$homeOrRehab == TRUE) |
  toupper(as.character(df$homeOrRehab)) %in% c("YES","HOME","TRUE","1")
)

# Site index
df$site <- as.integer(factor(df$siteID))
nSite <- length(unique(df$site))

# Time as integer
df$time <- as.integer(factor(df$Time2))

# Program indicator: 1 if Time2 >= 4 (post-implementation), 0 otherwise
df$program <- as.integer(df$time >= 4)

# Age: numeric (can be missing - will be imputed)
df$Age_num <- suppressWarnings(as.numeric(as.character(df$Age)))

# Female indicator
df$female <- as.integer(toupper(as.character(df$Gender)) == "FEMALE")

# EMS indicator
df$EMS_chr <- toupper(as.character(df$EMSvsCar))
df$ems <- as.integer(df$EMS_chr %in% c("EMS","1","TRUE","YES"))

# Treatment indicators
df$tpa <- as.integer(toupper(as.character(df$hadTPA)) %in% c("TRUE","1","YES"))
df$thr <- as.integer(toupper(as.character(df$hadThrombectomy)) %in% c("TRUE","1","YES"))

# For this model: only require non-missing outcome, site, and fully observed covariates
# Age can be missing (will be imputed based on Program, Female, EMS)
vars_essential <- c("y", "site", "program", "female", "ems", "tpa", "thr")
df_model <- df[complete.cases(df[, vars_essential]), ]

message("\nData summary:")
message("Total rows in original data: ", nrow(df))
message("Rows with complete essential variables: ", nrow(df_model))
message("Number of sites: ", nSite)
message("Missing Age values: ", sum(is.na(df_model$Age_num)))
message("\nOutcome distribution:")
print(table(df_model$y, useNA = "ifany"))

if (nrow(df_model) == 0) stop("No valid cases available for analysis")

# Standardize Age for better MCMC (use observed values only for standardization)
age_mean <- mean(df_model$Age_num, na.rm = TRUE)
age_sd <- sd(df_model$Age_num, na.rm = TRUE)
df_model$age_std <- (df_model$Age_num - age_mean) / age_sd

message("Age standardization: mean = ", round(age_mean, 2), ", sd = ", round(age_sd, 2))

# Create JAGS data list
data_jags <- list(
  N       = nrow(df_model),
  J       = nSite,
  y       = df_model$y,
  site    = df_model$site,
  program = df_model$program,
  age     = df_model$age_std,  # Can contain NA - will be imputed
  female  = df_model$female,
  ems     = df_model$ems,
  tpa     = df_model$tpa,
  thr     = df_model$thr
)

# ---------- 2. JAGS model matching specification ----------
model_text <- "
model {
  # ============================================
  # OUTCOME MODEL: Y_i ~ Bernoulli(p_i)
  # ============================================
  # logit(p_i) = α_j(i) + β_0 + β_1*Program_i + β_2*A_i + 
  #              β_3*Female_i + β_4*EMS_i + β_5*TPA_i + β_6*Thrombectomy_i
  
  for (i in 1:N) {
    y[i] ~ dbern(p[i])
    logit(p[i]) <- alpha[site[i]] + beta0 + 
                   beta1 * program[i] +
                   beta2 * age[i] +
                   beta3 * female[i] +
                   beta4 * ems[i] +
                   beta5 * tpa[i] +
                   beta6 * thr[i]
    
    # ============================================
    # AGE SUB-MODEL: A_i ~ N(μ_A,i, σ_A²)
    # ============================================
    # μ_A,i = γ_0 + γ_1*Female_i + γ_2*Program_i + γ_3*EMS_i
    # For observed Age, this contributes to likelihood
    # For missing Age, this is the imputation model
    
    age[i] ~ dnorm(mu_age[i], tau_age)
    mu_age[i] <- gamma0 + gamma1 * female[i] + gamma2 * program[i] + gamma3 * ems[i]
  }

  # ============================================
  # SITE RANDOM INTERCEPTS
  # ============================================
  # α_j ~ N(μ_α, σ_α²) for j = 1,...,J
  
  for (j in 1:J) {
    alpha[j] ~ dnorm(mu_alpha, tau_alpha)
  }

  # ============================================
  # PRIORS: Outcome Model Fixed Effects
  # ============================================
  # β_k ~ N(0, 10²) for k = 0,...,6
  
  beta0 ~ dnorm(0, 0.01)   # precision = 1/100 = 0.01
  beta1 ~ dnorm(0, 0.01)   # Program effect
  beta2 ~ dnorm(0, 0.01)   # Age effect
  beta3 ~ dnorm(0, 0.01)   # Female effect
  beta4 ~ dnorm(0, 0.01)   # EMS effect
  beta5 ~ dnorm(0, 0.01)   # TPA effect
  beta6 ~ dnorm(0, 0.01)   # Thrombectomy effect

  # ============================================
  # PRIORS: Age Model Fixed Effects
  # ============================================
  # γ_ℓ ~ N(0, 10²) for ℓ = 0,...,3
  
  gamma0 ~ dnorm(0, 0.01)  # Baseline age (intercept)
  gamma1 ~ dnorm(0, 0.01)  # Female effect on age
  gamma2 ~ dnorm(0, 0.01)  # Program effect on age
  gamma3 ~ dnorm(0, 0.01)  # EMS effect on age

  # ============================================
  # HYPERPRIORS: Random Effects
  # ============================================
  # μ_α ~ N(0, 10²)
  mu_alpha ~ dnorm(0, 0.01)
  
  # σ_α ~ Half-Normal(0, 2.5)
  sigma_alpha ~ dnorm(0, 0.16) T(0,)  # precision = 1/(2.5²) = 0.16
  tau_alpha <- pow(sigma_alpha, -2)

  # ============================================
  # HYPERPRIORS: Age Model Variance
  # ============================================
  # σ_A ~ Half-Normal(0, 20)
  sigma_age ~ dnorm(0, 0.0025) T(0,)  # precision = 1/(20²) = 0.0025
  tau_age <- pow(sigma_age, -2)
}
"
cat(model_text, file = "stroke_model_final.jags")
message("Wrote stroke_model_final.jags")

# ---------- 3. Initial values function ----------
inits_fn <- function() {
  # CRITICAL: Only provide initial values for MISSING age values
  # Observed age values must remain NA in the inits
  age_init <- rep(NA_real_, length(df_model$age_std))
  missing_idx <- which(is.na(df_model$age_std))
  
  # Only initialize where age is actually missing
  if (length(missing_idx) > 0) {
    age_init[missing_idx] <- 0  # Start missing ages at 0 (standardized mean)
  }
  
  list(
    beta0 = rnorm(1, 0, 0.1),
    beta1 = rnorm(1, 0, 0.1),
    beta2 = rnorm(1, 0, 0.1),
    beta3 = rnorm(1, 0, 0.1),
    beta4 = rnorm(1, 0, 0.1),
    beta5 = rnorm(1, 0, 0.1),
    beta6 = rnorm(1, 0, 0.1),
    gamma0 = 0,
    gamma1 = 0,
    gamma2 = 0,
    gamma3 = 0,
    mu_alpha = rnorm(1, 0, 0.5),
    sigma_alpha = runif(1, 0.1, 2),
    sigma_age = runif(1, 0.5, 2),
    alpha = rnorm(data_jags$J, 0, 0.5),
    age = age_init  # NA for observed, initial values for missing
  )
}

# Parameters to save
params <- c("beta0", "beta1", "beta2", "beta3", "beta4", "beta5", "beta6",
            "gamma0", "gamma1", "gamma2", "gamma3",
            "mu_alpha", "sigma_alpha", "sigma_age", "alpha")

# ---------- 4. Run JAGS ----------
set.seed(440)
message("\nRunning JAGS (4 chains, 20000 iterations, 10000 burn-in)...\n")

jags_out <- jags(
  data = data_jags,
  inits = inits_fn,
  parameters.to.save = params,
  model.file = "stroke_model_final.jags",
  n.chains = 4,
  n.iter = 20000,
  n.burnin = 10000,
  n.thin = 5,
  DIC = TRUE,
  progress.bar = "text"
)

print(jags_out)

# ---------- 5. Convergence diagnostics ----------
sims <- as.mcmc(jags_out)
sims_mat <- as.matrix(sims)

cat("\n=== CONVERGENCE DIAGNOSTICS ===\n")
cat("\n--- Gelman-Rubin diagnostics (Rhat, should be < 1.1) ---\n")
gelman_diag <- gelman.diag(sims, multivariate = FALSE)
print(gelman_diag)

psrf_values <- gelman_diag$psrf[,1]
if (any(psrf_values > 1.1, na.rm = TRUE)) {
  warning("Some parameters have Rhat > 1.1. Consider longer chains.")
  cat("\nParameters with poor convergence (Rhat > 1.1):\n")
  print(psrf_values[psrf_values > 1.1])
}

cat("\n--- Effective sample sizes ---\n")
ess <- effectiveSize(sims)
print(head(ess, 20))

if (any(ess < 400, na.rm = TRUE)) {
  warning("Some parameters have ESS < 400. Consider more iterations.")
}

# ---------- 6. Posterior summaries ----------
cat("\n=== POSTERIOR SUMMARIES ===\n")

cat("\n--- OUTCOME MODEL (Fixed Effects) ---\n")
outcome_params <- c("beta0", "beta1", "beta2", "beta3", "beta4", "beta5", "beta6")
outcome_labels <- c("Intercept", "Program", "Age", "Female", "EMS", "TPA", "Thrombectomy")
print(summary(sims[, outcome_params]))

cat("\n--- AGE MODEL (Fixed Effects) ---\n")
age_model_params <- c("gamma0", "gamma1", "gamma2", "gamma3")
age_labels <- c("Intercept", "Female", "Program", "EMS")
print(summary(sims[, age_model_params]))

cat("\n--- RANDOM EFFECTS (Hyperparameters) ---\n")
print(summary(sims[, c("mu_alpha", "sigma_alpha")]))

cat("\n--- AGE MODEL VARIANCE ---\n")
print(summary(sims[, "sigma_age"]))

cat("\n=== 95% CREDIBLE INTERVALS ===\n")
cat("\n--- Outcome Model ---\n")
for (i in 1:length(outcome_params)) {
  param <- outcome_params[i]
  ci <- quantile(sims_mat[, param], probs = c(0.025, 0.975))
  pm <- mean(sims_mat[, param])
  sig <- if(ci[1] > 0 || ci[2] < 0) " *" else ""
  cat(sprintf("%15s: %7.3f  [%7.3f, %7.3f]%s\n", outcome_labels[i], pm, ci[1], ci[2], sig))
}

cat("\n--- Age Model ---\n")
for (i in 1:length(age_model_params)) {
  param <- age_model_params[i]
  ci <- quantile(sims_mat[, param], probs = c(0.025, 0.975))
  pm <- mean(sims_mat[, param])
  sig <- if(ci[1] > 0 || ci[2] < 0) " *" else ""
  cat(sprintf("%15s: %7.3f  [%7.3f, %7.3f]%s\n", age_labels[i], pm, ci[1], ci[2], sig))
}

# ---------- 7. Interpret Age Model ----------
cat("\n=== AGE MODEL INTERPRETATION ===\n")
gamma1_pm <- mean(sims_mat[, "gamma1"])
gamma2_pm <- mean(sims_mat[, "gamma2"])
gamma3_pm <- mean(sims_mat[, "gamma3"])

cat("Baseline age (γ0): ", round(mean(sims_mat[, "gamma0"]), 3), " SD units\n")
cat("  On original scale: ", round(mean(sims_mat[, "gamma0"]) * age_sd + age_mean, 1), " years\n\n")

cat("Female effect (γ1): ", round(gamma1_pm, 3), " SD units\n")
cat("  Interpretation: Females are on average ", 
    abs(round(gamma1_pm * age_sd, 1)), " years ",
    ifelse(gamma1_pm > 0, "OLDER", "YOUNGER"), " than males\n")
cat("  95% CI: [", round(quantile(sims_mat[, "gamma1"], 0.025), 3), ", ",
    round(quantile(sims_mat[, "gamma1"], 0.975), 3), "]\n\n")

cat("Program effect (γ2): ", round(gamma2_pm, 3), " SD units\n")
cat("  Interpretation: Post-implementation patients are on average ",
    abs(round(gamma2_pm * age_sd, 1)), " years ",
    ifelse(gamma2_pm > 0, "OLDER", "YOUNGER"), " than baseline\n")
cat("  95% CI: [", round(quantile(sims_mat[, "gamma2"], 0.025), 3), ", ",
    round(quantile(sims_mat[, "gamma2"], 0.975), 3), "]\n\n")

cat("EMS effect (γ3): ", round(gamma3_pm, 3), " SD units\n")
cat("  Interpretation: EMS-transported patients are on average ",
    abs(round(gamma3_pm * age_sd, 1)), " years ",
    ifelse(gamma3_pm > 0, "OLDER", "YOUNGER"), " than car arrivals\n")
cat("  95% CI: [", round(quantile(sims_mat[, "gamma3"], 0.025), 3), ", ",
    round(quantile(sims_mat[, "gamma3"], 0.975), 3), "]\n\n")

cat("Age variability (σ_A): ", round(mean(sims_mat[, "sigma_age"]), 3), 
    " SD units (", round(mean(sims_mat[, "sigma_age"]) * age_sd, 1), " years)\n")

# ---------- 8. Model Performance ----------
cat("\n=== MODEL PERFORMANCE ===\n")

# Extract posterior mean ages (including imputed values)
age_cols <- grep("^age\\[", colnames(sims_mat), value = TRUE)
# Note: age posterior draws are not saved by default
# Use posterior mean from age model for missing values
alpha_names <- grep("^alpha\\[", colnames(sims_mat), value = TRUE)
alpha_pm <- colMeans(sims_mat[, alpha_names, drop = FALSE])

beta0_pm <- mean(sims_mat[, "beta0"])
beta1_pm <- mean(sims_mat[, "beta1"])
beta2_pm <- mean(sims_mat[, "beta2"])
beta3_pm <- mean(sims_mat[, "beta3"])
beta4_pm <- mean(sims_mat[, "beta4"])
beta5_pm <- mean(sims_mat[, "beta5"])
beta6_pm <- mean(sims_mat[, "beta6"])

gamma0_pm <- mean(sims_mat[, "gamma0"])
gamma1_pm <- mean(sims_mat[, "gamma1"])
gamma2_pm <- mean(sims_mat[, "gamma2"])
gamma3_pm <- mean(sims_mat[, "gamma3"])

# Impute missing ages using posterior mean
age_pm <- df_model$age_std
missing_age <- is.na(age_pm)
if (any(missing_age)) {
  age_pm[missing_age] <- gamma0_pm + 
                         gamma1_pm * df_model$female[missing_age] + 
                         gamma2_pm * df_model$program[missing_age] +
                         gamma3_pm * df_model$ems[missing_age]
  cat("Imputed ", sum(missing_age), " missing age values using posterior means\n")
}

# Compute predictions
linpred_pm <- beta0_pm + alpha_pm[data_jags$site] +
              beta1_pm * data_jags$program +
              beta2_pm * age_pm +
              beta3_pm * data_jags$female +
              beta4_pm * data_jags$ems +
              beta5_pm * data_jags$tpa +
              beta6_pm * data_jags$thr

p_pm <- plogis(linpred_pm)
df_model$pred_prob_postmean <- p_pm

cat("\nPredicted probability summary:\n")
print(summary(p_pm))

# AUC
roc_obj <- roc(df_model$y, df_model$pred_prob_postmean, quiet = TRUE)
auc_val <- auc(roc_obj)
cat("\nAUC (posterior mean predictions): ", round(auc_val, 4), "\n")

# ---------- 9. Save results ----------
saveRDS(jags_out, file = "stroke_jags_final.rds")
saveRDS(df_model, file = "stroke_with_preds_final.rds")
saveRDS(list(
  posterior_means = list(
    outcome_model = setNames(c(beta0_pm, beta1_pm, beta2_pm, beta3_pm, beta4_pm, beta5_pm, beta6_pm),
                              outcome_labels),
    age_model = setNames(c(gamma0_pm, gamma1_pm, gamma2_pm, gamma3_pm), age_labels),
    random_effects = list(
      mu_alpha = mean(sims_mat[, "mu_alpha"]),
      sigma_alpha = mean(sims_mat[, "sigma_alpha"])
    ),
    age_variance = mean(sims_mat[, "sigma_age"])
  ),
  credible_intervals_outcome = sapply(outcome_params, function(p) {
    quantile(sims_mat[, p], probs = c(0.025, 0.975))
  }),
  credible_intervals_age = sapply(age_model_params, function(p) {
    quantile(sims_mat[, p], probs = c(0.025, 0.975))
  }),
  auc = auc_val,
  convergence = gelman_diag,
  ess = ess,
  age_standardization = list(mean = age_mean, sd = age_sd)
), file = "model_results_final.rds")

message("\n=== ANALYSIS COMPLETE ===")
message("Files saved:")
message("  stroke_jags_final.rds")
message("  stroke_with_preds_final.rds")
message("  model_results_final.rds")
message("\nNote: * indicates 95% CI excludes 0 (significant effect)")

# =============================================================================
# Streamlined JAGS Model Diagnostics - New Age Sub-Model
# =============================================================================

library(R2jags)
library(coda)
library(pROC)
library(dplyr)

# Load results
jags_out <- readRDS("stroke_jags_final.rds")
df_model <- readRDS("stroke_with_preds_final.rds")
results <- readRDS("model_results_final.rds")

sims <- as.mcmc(jags_out)
sims_mat <- as.matrix(sims)

age_mean <- results$age_standardization$mean
age_sd <- results$age_standardization$sd

# =============================================================================
# CONVERGENCE DIAGNOSTICS
# =============================================================================

cat("\n=== CONVERGENCE DIAGNOSTICS ===\n")
outcome_params <- c("beta0", "beta1", "beta2", "beta3", "beta4", "beta5", "beta6")
age_params <- c("gamma0", "gamma1", "gamma2", "gamma3")
hyper_params <- c("mu_alpha", "sigma_alpha", "sigma_age")
all_params <- c(outcome_params, age_params, hyper_params)

# Gelman-Rubin
gelman_diag <- gelman.diag(sims[, all_params], multivariate = FALSE)
print(gelman_diag)

# Effective Sample Sizes
ess <- effectiveSize(sims[, all_params])
cat("\nEffective Sample Sizes:\n")
print(ess)

# Flag issues
bad_rhat <- gelman_diag$psrf[,1] > 1.1
bad_ess <- ess < 400
if (any(bad_rhat)) cat("\nWARNING: Rhat > 1.1 for:", names(which(bad_rhat)), "\n")
if (any(bad_ess)) cat("WARNING: ESS < 400 for:", names(which(bad_ess)), "\n")

# =============================================================================
# TRACE PLOTS
# =============================================================================

cat("\n=== TRACE PLOTS ===\n")

# Outcome model
par(mfrow = c(4, 2), mar = c(2, 2, 2, 1))
for (p in outcome_params) {
  traceplot(sims[, p], main = p, col = c("red", "blue", "green", "purple"))
}

# Age model
par(mfrow = c(2, 2), mar = c(2, 2, 2, 1))
for (p in age_params) {
  traceplot(sims[, p], main = p, col = c("red", "blue", "green", "purple"))
}

# Hyperparameters
par(mfrow = c(2, 2), mar = c(2, 2, 2, 1))
for (p in hyper_params) {
  traceplot(sims[, p], main = p, col = c("red", "blue", "green", "purple"))
}

# =============================================================================
# POSTERIOR DENSITIES
# =============================================================================

cat("\n=== POSTERIOR DENSITIES ===\n")

# Outcome model
par(mfrow = c(4, 2), mar = c(2, 2, 2, 1))
for (p in outcome_params) {
  densplot(sims[, p], main = p, col = c("red", "blue", "green", "purple"))
  abline(v = 0, lty = 2, col = "black", lwd = 2)
}

# Age model
par(mfrow = c(2, 2), mar = c(2, 2, 2, 1))
for (p in age_params) {
  densplot(sims[, p], main = p, col = c("red", "blue", "green", "purple"))
  abline(v = 0, lty = 2, col = "black", lwd = 2)
}

# =============================================================================
# RESIDUAL DIAGNOSTICS
# =============================================================================

cat("\n=== RESIDUAL DIAGNOSTICS ===\n")

# Extract posterior means
alpha_names <- grep("^alpha\\[", colnames(sims_mat), value = TRUE)
alpha_pm <- colMeans(sims_mat[, alpha_names, drop = FALSE])

beta_pm <- colMeans(sims_mat[, outcome_params])
gamma_pm <- colMeans(sims_mat[, age_params])

# Impute missing ages
age_for_pred <- df_model$age_std
missing_age <- is.na(age_for_pred)
if (any(missing_age)) {
  age_for_pred[missing_age] <- gamma_pm[1] + 
                                gamma_pm[2] * df_model$female[missing_age] + 
                                gamma_pm[3] * df_model$program[missing_age] +
                                gamma_pm[4] * df_model$ems[missing_age]
  cat("Imputed", sum(missing_age), "missing ages\n")
}

# Compute fitted values
linpred <- beta_pm[1] + alpha_pm[df_model$site] +
           beta_pm[2] * df_model$program +
           beta_pm[3] * age_for_pred +
           beta_pm[4] * df_model$female +
           beta_pm[5] * df_model$ems +
           beta_pm[6] * df_model$tpa +
           beta_pm[7] * df_model$thr

fitted_prob <- plogis(linpred)

# Residuals
deviance_resid <- sign(df_model$y - fitted_prob) * 
                  sqrt(-2 * (df_model$y * log(fitted_prob + 1e-10) + 
                             (1 - df_model$y) * log(1 - fitted_prob + 1e-10)))

pearson_resid <- (df_model$y - fitted_prob) / sqrt(fitted_prob * (1 - fitted_prob) + 1e-10)

cat("\nDeviance Residuals Summary:\n")
print(summary(deviance_resid))

# Residual plots
par(mfrow = c(2, 3), mar = c(3, 3, 2, 1))

plot(fitted_prob, deviance_resid, pch = 16, col = rgb(0,0,0,0.3),
     xlab = "Fitted Probability", ylab = "Deviance Residuals",
     main = "Residuals vs Fitted")
abline(h = 0, col = "red", lwd = 2, lty = 2)
lines(lowess(fitted_prob, deviance_resid), col = "blue", lwd = 2)

plot(age_for_pred, deviance_resid, pch = 16, col = rgb(0,0,0,0.3),
     xlab = "Age (std)", ylab = "Deviance Residuals",
     main = "Residuals vs Age")
abline(h = 0, col = "red", lwd = 2, lty = 2)
lines(lowess(age_for_pred, deviance_resid), col = "blue", lwd = 2)

boxplot(deviance_resid ~ df_model$program, col = c("lightblue", "lightgreen"),
        xlab = "Program", ylab = "Deviance Residuals", main = "By Program")
abline(h = 0, col = "red", lwd = 2, lty = 2)

boxplot(deviance_resid ~ df_model$site, col = rainbow(9),
        xlab = "Site", ylab = "Deviance Residuals", main = "By Site")
abline(h = 0, col = "red", lwd = 2, lty = 2)

qqnorm(deviance_resid, pch = 16, col = rgb(0,0,0,0.5), main = "QQ Plot")
qqline(deviance_resid, col = "red", lwd = 2)

hist(deviance_resid, breaks = 30, col = "lightblue", border = "white",
     main = "Residual Distribution", xlab = "Deviance Residuals", freq = FALSE)
curve(dnorm(x, mean(deviance_resid), sd(deviance_resid)), add = TRUE, col = "red", lwd = 2)

# =============================================================================
# MODEL PERFORMANCE
# =============================================================================

cat("\n=== MODEL PERFORMANCE ===\n")

# ROC/AUC
roc_obj <- roc(df_model$y, fitted_prob, quiet = TRUE)
auc_val <- auc(roc_obj)

# Confusion matrix
pred_class <- ifelse(fitted_prob > 0.5, 1, 0)
conf_mat <- table(Predicted = pred_class, Actual = df_model$y)

accuracy <- sum(diag(conf_mat)) / sum(conf_mat)
sensitivity <- conf_mat[2, 2] / sum(conf_mat[, 2])
specificity <- conf_mat[1, 1] / sum(conf_mat[, 1])

cat("\nAUC:", round(auc_val, 4))
cat("\nAccuracy:", round(accuracy, 4))
cat("\nSensitivity:", round(sensitivity, 4))
cat("\nSpecificity:", round(specificity, 4))
cat("\n\nConfusion Matrix:\n")
print(conf_mat)

# Plots
par(mfrow = c(1, 2), mar = c(4, 4, 2, 1))

plot(roc_obj, col = "blue", lwd = 2, main = paste0("ROC (AUC=", round(auc_val, 3), ")"))
abline(a = 0, b = 1, lty = 2, col = "red")

# Calibration
df_model$prob_bin <- cut(fitted_prob, breaks = 10, include.lowest = TRUE)
cal_data <- df_model %>%
  group_by(prob_bin) %>%
  summarise(observed = mean(y), predicted = mean(fitted_prob), n = n())

plot(cal_data$predicted, cal_data$observed, xlim = c(0,1), ylim = c(0,1),
     pch = 16, cex = sqrt(cal_data$n)/3, col = "blue",
     xlab = "Predicted", ylab = "Observed", main = "Calibration")
abline(a = 0, b = 1, col = "red", lwd = 2, lty = 2)

# =============================================================================
# POSTERIOR PREDICTIVE CHECK
# =============================================================================

cat("\n=== POSTERIOR PREDICTIVE CHECK ===\n")

n_sim <- 100
n_obs <- nrow(df_model)
y_rep <- matrix(NA, n_sim, n_obs)

for (i in 1:n_sim) {
  idx <- sample(nrow(sims_mat), 1)
  beta_s <- sims_mat[idx, outcome_params]
  alpha_s <- sims_mat[idx, alpha_names]
  
  linpred_s <- beta_s[1] + alpha_s[df_model$site] +
               beta_s[2] * df_model$program +
               beta_s[3] * age_for_pred +
               beta_s[4] * df_model$female +
               beta_s[5] * df_model$ems +
               beta_s[6] * df_model$tpa +
               beta_s[7] * df_model$thr
  
  y_rep[i, ] <- rbinom(n_obs, 1, plogis(linpred_s))
}

mean_obs <- mean(df_model$y)
mean_rep <- rowMeans(y_rep)
ppp_mean <- mean(mean_rep >= mean_obs)

cat("Observed mean:", round(mean_obs, 3))
cat("\nReplicated mean:", round(mean(mean_rep), 3))
cat("\nPosterior predictive p-value:", round(ppp_mean, 3))
cat(" (should be ~0.5)\n")

par(mfrow = c(2, 2), mar = c(3, 3, 2, 1))

hist(df_model$y, breaks = 2, col = rgb(1,0,0,0.5), main = "Observed vs Replicated",
     xlab = "Outcome", xlim = c(-0.5,1.5), freq = FALSE)
for (i in 1:20) hist(y_rep[i,], breaks = 2, add = TRUE, col = rgb(0,0,1,0.05), freq = FALSE)

hist(mean_rep, col = "lightblue", main = "Replicated Means", xlab = "Mean")
abline(v = mean_obs, col = "red", lwd = 3)

sd_rep <- apply(y_rep, 1, sd)
hist(sd_rep, col = "lightgreen", main = "Replicated SDs", xlab = "SD")
abline(v = sd(df_model$y), col = "red", lwd = 3)

plot(mean_rep, sd_rep, pch = 16, col = rgb(0,0,0,0.5),
     xlab = "Mean", ylab = "SD", main = "Mean-SD Relationship")
points(mean_obs, sd(df_model$y), pch = 16, col = "red", cex = 2)

# =============================================================================
# AGE MODEL DIAGNOSTICS
# =============================================================================

cat("\n=== AGE MODEL DIAGNOSTICS ===\n")

cat("\nAge Effects (on standardized scale):\n")
for (i in 1:length(age_params)) {
  ci <- quantile(sims_mat[, age_params[i]], probs = c(0.025, 0.975))
  pm <- mean(sims_mat[, age_params[i]])
  sig <- if(ci[1] > 0 || ci[2] < 0) " *" else ""
  cat(sprintf("  %s: %.3f [%.3f, %.3f]%s\n", 
              c("Intercept","Female","Program","EMS")[i], pm, ci[1], ci[2], sig))
}

cat("\nInterpretation (in years):\n")
cat("  Female effect:", round(gamma_pm[2] * age_sd, 1), "years\n")
cat("  Program effect:", round(gamma_pm[3] * age_sd, 1), "years\n")
cat("  EMS effect:", round(gamma_pm[4] * age_sd, 1), "years\n")

par(mfrow = c(2, 2), mar = c(3, 3, 2, 1))

# Age by covariates
age_obs <- df_model$age_std[!is.na(df_model$age_std)]
hist(age_obs, breaks = 30, col = "lightblue", main = "Observed Age Distribution",
     xlab = "Age (std)", freq = FALSE)
curve(dnorm(x, mean(age_obs), sd(age_obs)), add = TRUE, col = "red", lwd = 2)

boxplot(age_std ~ female, data = df_model, col = c("lightblue", "pink"),
        names = c("Male", "Female"), ylab = "Age (std)", main = "Age by Gender")

boxplot(age_std ~ program, data = df_model, col = c("lightblue", "lightgreen"),
        names = c("Baseline", "Post"), ylab = "Age (std)", main = "Age by Program")

boxplot(age_std ~ ems, data = df_model, col = c("lightblue", "orange"),
        names = c("Car", "EMS"), ylab = "Age (std)", main = "Age by Transport")

# =============================================================================
# ACF PLOTS
# =============================================================================

cat("\n=== ACF PLOTS ===\n")

# Outcome model
par(mfrow = c(4, 2), mar = c(2, 2, 2, 1))
for (p in outcome_params) {
  acf(sims_mat[, p], main = paste("ACF:", p), lag.max = 50)
}

# Age model
par(mfrow = c(2, 2), mar = c(2, 2, 2, 1))
for (p in age_params) {
  acf(sims_mat[, p], main = paste("ACF:", p), lag.max = 50)
}

# Hyperparameters
par(mfrow = c(2, 2), mar = c(2, 2, 2, 1))
for (p in hyper_params) {
  acf(sims_mat[, p], main = paste("ACF:", p), lag.max = 50)
}

# =============================================================================
# SUMMARY
# =============================================================================

cat("\n=== SUMMARY ===\n")
cat("AUC:", round(auc_val, 3), "\n")
cat("Convergence:", ifelse(all(!bad_rhat), "Good", "Issues detected"), "\n")
cat("Model fit (PPP):", ifelse(abs(ppp_mean - 0.5) < 0.3, "Good", "Check fit"), "\n")
cat("\nDiagnostics complete.\n")
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Figure 1. ROC curve for the model."}
# ROC / AUC
df_imputed <- df_imputed %>% mutate(pred_prob_phase = predict(final_glm_phase, type = "response"))
roc_obj <- pROC::roc(df_imputed$homeOrRehab_num, df_imputed$pred_prob_phase, quiet = TRUE)
plot(roc_obj, main = paste0("ROC (AUC = ", round(as.numeric(pROC::auc(roc_obj)),3), ")"))
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Figure 2. Residuals of Age."}
library(tidyverse)

# Compute residuals and fitted values

diag_df <- df_imputed %>%
mutate(
fitted = predict(final_glm_phase, type = "response"),
dev_resid = residuals(final_glm_phase, type = "deviance")
)

# Plot residuals vs Age

ggplot(diag_df, aes(x = Age_imp, y = dev_resid)) +
geom_hline(yintercept = 0, color = "gray50") +
geom_point(alpha = 0.4, size = 1.3) +
geom_smooth(method = "loess", se = FALSE, color = "red") +
labs(
title = "Residuals vs Age",
x = "Age",
y = "Deviance residual"
) +
theme_minimal()
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Figure 3. QQ-plot of deviance residuals (look for departures from Normal."}
# 2) QQ-plot of deviance residuals (look for departures from Normal)
p2 <- ggplot(diag_df, aes(sample = dev_resid)) +
  stat_qq(alpha = 0.6) +
  stat_qq_line(color = "darkblue") +
  labs(title = "QQ-plot of deviance residuals") +
  theme_minimal()

p2
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, tbl-cap="Table 1. 95% Credible Intervals."}

cat("\n=== 95% CREDIBLE INTERVALS ===\n")
cat("\n--- Outcome Model ---\n")
for (i in 1:length(outcome_params)) {
  param <- outcome_params[i]
  ci <- quantile(sims_mat[, param], probs = c(0.025, 0.975))
  pm <- mean(sims_mat[, param])
  sig <- if(ci[1] > 0 || ci[2] < 0) " *" else ""
  cat(sprintf("%15s: %7.3f  [%7.3f, %7.3f]%s\n", outcome_labels[i], pm, ci[1], ci[2], sig))
}
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Figure 4. ROC/AUC for Bayesian Model."}
# ROC/AUC

plot(roc_obj, col = "blue", lwd = 2, main = paste0("ROC (AUC=", round(auc_val, 3), ")"))
abline(a = 0, b = 1, lty = 2, col = "red")
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Figure 5. Residuals vs. Fitted."}
plot(fitted_prob, deviance_resid, pch = 16, col = rgb(0,0,0,0.3),
     xlab = "Fitted Probability", ylab = "Deviance Residuals",
     main = "Residuals vs Fitted")
abline(h = 0, col = "red", lwd = 2, lty = 2)
lines(lowess(fitted_prob, deviance_resid), col = "blue", lwd = 2)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Figure 6. Residuals vs. Age."}
plot(age_for_pred, deviance_resid, pch = 16, col = rgb(0,0,0,0.3),
     xlab = "Age (std)", ylab = "Deviance Residuals",
     main = "Residuals vs Age")
abline(h = 0, col = "red", lwd = 2, lty = 2)
lines(lowess(age_for_pred, deviance_resid), col = "blue", lwd = 2)

```

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Figure 7. Residuals by Site."}
boxplot(deviance_resid ~ df_model$site, col = rainbow(9),
        xlab = "Site", ylab = "Deviance Residuals", main = "By Site")
abline(h = 0, col = "red", lwd = 2, lty = 2)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Figure 8. QQ Plot for Bayesian Model"}
qqnorm(deviance_resid, pch = 16, col = rgb(0,0,0,0.5), main = "QQ Plot")
qqline(deviance_resid, col = "red", lwd = 2)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Figure 9. Effective Sample Sizes"}
# =============================================================================
# CONVERGENCE DIAGNOSTICS
# =============================================================================

# Effective Sample Sizes
ess <- effectiveSize(sims[, all_params])
cat("\nEffective Sample Sizes:\n")
print(ess)

```

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Figure 10. Trace Plots of Beta"}

# Outcome model
par(mfrow = c(4, 2), mar = c(2, 2, 2, 1))
for (p in outcome_params) {
  traceplot(sims[, p], main = p, col = c("red", "blue", "green", "purple"))
}

```

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Figure 11. Trace Plots of Gamma"}
# Age model
par(mfrow = c(2, 2), mar = c(2, 2, 2, 1))
for (p in age_params) {
  traceplot(sims[, p], main = p, col = c("red", "blue", "green", "purple"))
}
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Figure 12. Trace Plots of Hyperparameters"}
# Hyperparameters
par(mfrow = c(2, 2), mar = c(2, 2, 2, 1))
for (p in hyper_params) {
  traceplot(sims[, p], main = p, col = c("red", "blue", "green", "purple"))
}
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Figure 13. ACF Plots of Outcome Model"}
# Outcome model
par(mfrow = c(4, 2), mar = c(2, 2, 2, 1))
for (p in outcome_params) {
  acf(sims_mat[, p], main = paste("ACF:", p), lag.max = 50)
}
```
